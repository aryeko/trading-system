# S-02: Data Provider Layer and Raw Persistence

**Last updated:** 2025-09-21

## Outcome
- Introduce an abstract `DataProvider` interface and at least one concrete adapter (Yahoo Finance by default) capable of fetching OHLCV data and optional benchmarks.
- Persist raw pulls and metadata exactly as described in the workflow: `/data/raw/YYYY-MM-DD/<symbol>.parquet` and `meta_run.json`.

## Deliverables
- `trading_system.data.provider` module defining the canonical column order (`BARS_COLUMN_ORDER`), validation helpers (`ensure_bars_frame`, `empty_bars_frame`), `ProviderRequest`, and `DataUnavailableError`.
- `trading_system.data.yahoo.YahooDataProvider` implementation with resilient error handling and deterministic output schema.
- `trading_system.data.storage.RawDataWriter` that performs atomic parquet writes and produces a `DataRunMeta` summary record.
- High-level `run_data_pull` service orchestrating provider calls and persistence.
- CLI command `ts data pull --config configs/sample-config.yml --provider yahoo --asof 2024-05-02 [--skip-benchmark]` using the active config to fetch data and write artifacts.

## Functional Requirements
- `DataProvider.get_bars` must return a DataFrame with `BARS_COLUMN_ORDER` columns, sorted by symbol/date, and deduplicated rows.
- Benchmark fetching is optional but, when available, persists as `benchmark_<SYMBOL>.parquet` alongside equities.
- Raw files must be written atomically: write to a temporary file in the same directory and `rename` into place to avoid partial files on failure.
- `meta_run.json` captures ISO8601 timestamp, sorted universe list, benchmark symbol, requested window (`start`, `end`), and last bar date.
- When symbols are unavailable, log a structured warning and continue processing remaining symbols.

## CLI Additions
- `poetry run ts data pull --config <path> --provider yahoo --asof YYYY-MM-DD` executes the full pull, logging skipped symbols and the output directory.
- `poetry run ts data providers` lists available adapters (`yahoo`, `eodhd`, stubs) and their capabilities.
- `poetry run ts data inspect --run data/raw/YYYY-MM-DD` summarizes the saved parquet files and meta payload for debugging.

## Verification
1. Prepare a fixture config pointing `paths.data_raw` to a temp directory and universe to two tickers plus a benchmark.
2. Run `poetry run ts data pull --config <config> --asof 2024-05-02`; confirm the command exits zero and logs pulled symbols.
3. Inspect `data/raw/2024-05-02/meta_run.json`; ensure timestamp reflects execution time, symbols sorted alphabetically, benchmark recorded, and `start` equals `asof - lookback_days`.
4. Load one generated parquet file in pandas and confirm column order matches `BARS_COLUMN_ORDER` with expected dtypes (string ticker, datetime index, nullable volume).
5. Execute `pytest tests/test_data_provider.py` to validate provider parsing, persistence determinism, and benchmark handling.

## Dependencies
- S-01.

## Notes
- Future providers (paid data sources) must plug into the same interface; add stubs or feature flags instead of branching logic when possible.
